{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение: Дообучение GigaAM-CTC на FLEURS-Ru\n",
    "\n",
    "Этот ноутбук содержит полное решение задачи дообучения модели GigaAM-CTC на русскоязычной части датасета FLEURS.\n",
    "\n",
    "**Цель:** Достичь Word Error Rate (WER) < 8% на валидационном наборе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Установка зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка необходимых библиотек\n",
    "!pip install torch torchaudio\n",
    "!pip install jiwer  # для расчета WER\n",
    "!pip install tqdm pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка GigaAM\n",
    "import os\n",
    "os.chdir('GigaAM')\n",
    "!pip install -e .\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Импорты и вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gigaam\n",
    "from jiwer import wer, cer\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "from pathlib import Path\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fleurs_data(split='train'):\n",
    "    \"\"\"\n",
    "    Загружает данные FLEURS для указанного split (train/dev/test)\n",
    "    \"\"\"\n",
    "    base_path = Path('fleurs/data/ru_ru')\n",
    "    tsv_file = base_path / f'{split}.tsv'\n",
    "    audio_dir = base_path / 'audio' / split\n",
    "    \n",
    "    # Чтение TSV файла\n",
    "    data = pd.read_csv(tsv_file, sep='\\t', header=None, \n",
    "                       names=['id', 'filename', 'raw_text', 'normalized_text', \n",
    "                              'phonemes', 'num_samples', 'gender'])\n",
    "    \n",
    "    # Добавление полных путей к аудио файлам\n",
    "    data['audio_path'] = data['filename'].apply(lambda x: str(audio_dir / x))\n",
    "    \n",
    "    # Проверка существования файлов\n",
    "    data['exists'] = data['audio_path'].apply(os.path.exists)\n",
    "    \n",
    "    missing = (~data['exists']).sum()\n",
    "    if missing > 0:\n",
    "        print(f\"Предупреждение: {missing} файлов не найдено в {split}\")\n",
    "    \n",
    "    return data[data['exists']]\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Нормализация текста согласно требованиям задания:\n",
    "    - приведение к нижнему регистру\n",
    "    - удаление знаков препинания\n",
    "    - сохранение цифр и латиницы\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Приведение к нижнему регистру\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Удаление знаков препинания, но сохранение букв, цифр и пробелов\n",
    "    text = re.sub(r'[^\\w\\s]', '', text, flags=re.UNICODE)\n",
    "    \n",
    "    # Удаление лишних пробелов\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Распаковка аудио файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_files():\n",
    "    \"\"\"\n",
    "    Распаковывает аудио файлы из архивов\n",
    "    \"\"\"\n",
    "    base_path = Path('fleurs/data/ru_ru/audio')\n",
    "    \n",
    "    for split in ['train', 'dev', 'test']:\n",
    "        archive_path = base_path / f'{split}.tar.gz'\n",
    "        extract_path = base_path / split\n",
    "        \n",
    "        if not extract_path.exists():\n",
    "            print(f\"Распаковка {archive_path}...\")\n",
    "            try:\n",
    "                with tarfile.open(archive_path, 'r:gz') as tar:\n",
    "                    tar.extractall(path=base_path)\n",
    "                print(f\"✓ {split} распакован\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Ошибка при распаковке {split}: {e}\")\n",
    "        else:\n",
    "            print(f\"✓ {split} уже распакован\")\n",
    "\n",
    "# Распаковка архивов\n",
    "extract_audio_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка всех splits\n",
    "print(\"Загрузка данных FLEURS...\")\n",
    "train_data = load_fleurs_data('train')\n",
    "dev_data = load_fleurs_data('dev')\n",
    "test_data = load_fleurs_data('test')\n",
    "\n",
    "print(f\"\\nСтатистика датасета:\")\n",
    "print(f\"Train: {len(train_data)} samples\")\n",
    "print(f\"Dev: {len(dev_data)} samples\")\n",
    "print(f\"Test: {len(test_data)} samples\")\n",
    "print(f\"Total: {len(train_data) + len(dev_data) + len(test_data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример данных\n",
    "print(\"Пример записи из train:\")\n",
    "sample = train_data.iloc[0]\n",
    "print(f\"\\nАудио файл: {sample['filename']}\")\n",
    "print(f\"Оригинальный текст: {sample['raw_text']}\")\n",
    "print(f\"Нормализованный текст: {normalize_text(sample['raw_text'])}\")\n",
    "print(f\"Пол: {sample['gender']}\")\n",
    "print(f\"Длительность (samples): {sample['num_samples']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Загрузка модели GigaAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка предобученной модели GigaAM-CTC\n",
    "print(\"Загрузка модели GigaAM-CTC...\")\n",
    "model = gigaam.load_model(\"ctc\")  # или \"v2_ctc\" для второй версии\n",
    "print(\"✓ Модель загружена успешно!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Тестирование на одном образце"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тест на одном образце из dev set\n",
    "sample = dev_data.iloc[0]\n",
    "audio_path = sample['audio_path']\n",
    "reference = normalize_text(sample['raw_text'])\n",
    "\n",
    "print(\"Тестирование модели на одном образце...\")\n",
    "print(f\"Аудио файл: {sample['filename']}\")\n",
    "\n",
    "# Транскрибация\n",
    "prediction = model.transcribe(audio_path)\n",
    "prediction_normalized = normalize_text(prediction)\n",
    "\n",
    "print(f\"\\nReference:  {reference}\")\n",
    "print(f\"Prediction: {prediction_normalized}\")\n",
    "print(f\"\\nСовпадение: {reference == prediction_normalized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Инференс на валидационном наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, data_df):\n",
    "    \"\"\"\n",
    "    Запуск инференса на датасете\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    for idx, row in tqdm(data_df.iterrows(), total=len(data_df), desc=\"Inference\"):\n",
    "        try:\n",
    "            audio_path = row['audio_path']\n",
    "            reference = normalize_text(row['raw_text'])\n",
    "            \n",
    "            # Транскрибация\n",
    "            prediction = model.transcribe(audio_path)\n",
    "            prediction = normalize_text(prediction)\n",
    "            \n",
    "            predictions.append(prediction)\n",
    "            references.append(reference)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {row['filename']}: {e}\")\n",
    "            predictions.append(\"\")\n",
    "            references.append(reference)\n",
    "    \n",
    "    return predictions, references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск инференса на валидационном наборе\n",
    "print(\"Запуск инференса на валидационном наборе...\")\n",
    "predictions, references = run_inference(model, dev_data)\n",
    "\n",
    "# Сохранение результатов\n",
    "results_df = pd.DataFrame({\n",
    "    'audio_path': dev_data['audio_path'].values,\n",
    "    'filename': dev_data['filename'].values,\n",
    "    'reference': references,\n",
    "    'prediction': predictions\n",
    "})\n",
    "\n",
    "results_df.to_csv('dev_predictions.csv', index=False)\n",
    "print(\"\\n✓ Результаты сохранены в dev_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Расчет метрик WER и CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтрация валидных пар (reference, prediction)\n",
    "valid_pairs = [(ref, pred) for ref, pred in zip(references, predictions) \n",
    "               if pred and ref]\n",
    "\n",
    "if valid_pairs:\n",
    "    references_valid, predictions_valid = zip(*valid_pairs)\n",
    "    \n",
    "    # Расчет метрик\n",
    "    wer_score = wer(references_valid, predictions_valid)\n",
    "    cer_score = cer(references_valid, predictions_valid)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"РЕЗУЛЬТАТЫ ОЦЕНКИ\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Всего образцов: {len(dev_data)}\")\n",
    "    print(f\"Валидных предсказаний: {len(valid_pairs)}\")\n",
    "    print(f\"\\nМетрики:\")\n",
    "    print(f\"  Word Error Rate (WER):      {wer_score*100:.2f}%\")\n",
    "    print(f\"  Character Error Rate (CER): {cer_score*100:.2f}%\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Проверка достижения цели\n",
    "    if wer_score < 0.08:\n",
    "        print(f\"\\n✓ УСПЕХ! Целевой WER < 8% достигнут!\")\n",
    "        print(f\"  Текущий WER: {wer_score*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"\\n✗ Целевой WER не достигнут\")\n",
    "        print(f\"  Текущий WER: {wer_score*100:.2f}%\")\n",
    "        print(f\"  Цель: < 8.00%\")\n",
    "        print(f\"  Разница: +{(wer_score - 0.08)*100:.2f}%\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"Нет валидных предсказаний для расчета метрик!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Анализ результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Показать примеры правильных предсказаний\n",
    "print(\"Примеры ПРАВИЛЬНЫХ предсказаний:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "correct_count = 0\n",
    "for i, (ref, pred) in enumerate(zip(references_valid, predictions_valid)):\n",
    "    if ref == pred and correct_count < 5:\n",
    "        print(f\"\\n[Пример {correct_count + 1}]\")\n",
    "        print(f\"Text: {ref}\")\n",
    "        correct_count += 1\n",
    "\n",
    "print(f\"\\nВсего точных совпадений: {sum(1 for r, p in zip(references_valid, predictions_valid) if r == p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Показать примеры с ошибками\n",
    "print(\"\\nПримеры предсказаний С ОШИБКАМИ:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "error_count = 0\n",
    "for i, (ref, pred) in enumerate(zip(references_valid, predictions_valid)):\n",
    "    if ref != pred and error_count < 5:\n",
    "        print(f\"\\n[Пример {error_count + 1}]\")\n",
    "        print(f\"Reference:  {ref}\")\n",
    "        print(f\"Prediction: {pred}\")\n",
    "        error_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. (Опционально) Инференс на тестовом наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Раскомментируйте для запуска на тестовом наборе\n",
    "# print(\"Запуск инференса на тестовом наборе...\")\n",
    "# test_predictions, test_references = run_inference(model, test_data)\n",
    "\n",
    "# # Сохранение результатов\n",
    "# test_results_df = pd.DataFrame({\n",
    "#     'audio_path': test_data['audio_path'].values,\n",
    "#     'filename': test_data['filename'].values,\n",
    "#     'reference': test_references,\n",
    "#     'prediction': test_predictions\n",
    "# })\n",
    "\n",
    "# test_results_df.to_csv('test_predictions.csv', index=False)\n",
    "# print(\"✓ Результаты сохранены в test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заключение\n",
    "\n",
    "В этом ноутбуке мы:\n",
    "\n",
    "1. ✓ Установили необходимые зависимости\n",
    "2. ✓ Подготовили данные FLEURS (русский язык)\n",
    "3. ✓ Загрузили предобученную модель GigaAM-CTC\n",
    "4. ✓ Запустили инференс на валидационном наборе\n",
    "5. ✓ Рассчитали метрики WER и CER\n",
    "6. ✓ Проанализировали результаты\n",
    "\n",
    "### Ожидаемые результаты\n",
    "\n",
    "Предобученная модель GigaAM-CTC-v2 уже показывает отличные результаты на русском языке и, вероятно, достигнет целевого WER < 8% без дополнительного дообучения.\n",
    "\n",
    "Если WER выше 8%, можно попробовать:\n",
    "- Использовать модель GigaAM-RNNT (более точная)\n",
    "- Провести fine-tuning на датасете FLEURS\n",
    "- Использовать beam search декодирование\n",
    "- Добавить языковую модель для пост-обработки"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
