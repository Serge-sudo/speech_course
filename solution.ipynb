{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение: Дообучение GigaAM-CTC на FLEURS-Ru\n",
    "\n",
    "Этот ноутбук содержит полное решение задачи дообучения модели GigaAM-CTC на русскоязычной части датасета FLEURS.\n",
    "\n",
    "**Цель:** Достичь Word Error Rate (WER) < 8% на валидационном наборе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Установка зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка необходимых библиотек\n",
    "!pip install torch torchaudio\n",
    "!pip install datasets  # для загрузки FLEURS\n",
    "!pip install jiwer  # для расчета WER\n",
    "!pip install tqdm pandas soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка GigaAM\n",
    "import os\n",
    "os.chdir('GigaAM')\n",
    "!pip install -e .\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Импорты и вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gigaam\n",
    "from jiwer import wer, cer\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "import tempfile\n",
    "import soundfile as sf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fleurs_data(split='train'):\n",
    "    \"\"\"\n",
    "    Загружает данные FLEURS для указанного split (train/validation/test)\n",
    "    используя библиотеку datasets от HuggingFace\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Преобразуем 'dev' в 'validation' для совместимости\n",
    "    dataset_split = 'validation' if split == 'dev' else split\n",
    "    \n",
    "    print(f\"Загрузка FLEURS (ru_ru, {dataset_split}) из HuggingFace...\")\n",
    "    \n",
    "    # Временно переименовываем fleurs.py чтобы избежать конфликта\n",
    "    fleurs_script = 'fleurs/fleurs.py'\n",
    "    fleurs_backup = 'fleurs/fleurs.py.bak'\n",
    "    \n",
    "    renamed = False\n",
    "    if os.path.exists(fleurs_script):\n",
    "        try:\n",
    "            os.rename(fleurs_script, fleurs_backup)\n",
    "            renamed = True\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    try:\n",
    "        dataset = load_dataset(\"google/fleurs\", \"ru_ru\", split=dataset_split)\n",
    "    finally:\n",
    "        # Восстанавливаем файл\n",
    "        if renamed and os.path.exists(fleurs_backup):\n",
    "            try:\n",
    "                os.rename(fleurs_backup, fleurs_script)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Преобразование в DataFrame\n",
    "    data_list = []\n",
    "    for item in dataset:\n",
    "        data_list.append({\n",
    "            'id': item['id'],\n",
    "            'audio_array': item['audio']['array'],\n",
    "            'sampling_rate': item['audio']['sampling_rate'],\n",
    "            'raw_text': item['raw_transcription'],\n",
    "            'transcription': item['transcription'],\n",
    "            'num_samples': item['num_samples'],\n",
    "            'gender': item['gender']\n",
    "        })\n",
    "    \n",
    "    data = pd.DataFrame(data_list)\n",
    "    print(f\"✓ Загружено {len(data)} образцов\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Загрузка данных FLEURS\n",
    "\n",
    "Датасет загружается напрямую из HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка всех splits\n",
    "print(\"Загрузка данных FLEURS...\")\n",
    "train_data = load_fleurs_data('train')\n",
    "dev_data = load_fleurs_data('dev')\n",
    "test_data = load_fleurs_data('test')\n",
    "\n",
    "print(f\"\\nСтатистика датасета:\")\n",
    "print(f\"Train: {len(train_data)} samples\")\n",
    "print(f\"Validation: {len(dev_data)} samples\")\n",
    "print(f\"Test: {len(test_data)} samples\")\n",
    "print(f\"Total: {len(train_data) + len(dev_data) + len(test_data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример данных\n",
    "print(\"Пример записи из train:\")\n",
    "sample = train_data.iloc[0]\n",
    "print(f\"\\nID: {sample['id']}\")\n",
    "print(f\"Оригинальный текст: {sample['raw_text']}\")\n",
    "print(f\"Нормализованный текст: {normalize_text(sample['raw_text'])}\")\n",
    "print(f\"Пол: {sample['gender']}\")\n",
    "print(f\"Sampling rate: {sample['sampling_rate']} Hz\")\n",
    "print(f\"Длина аудио: {len(sample['audio_array'])} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Загрузка модели GigaAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка предобученной модели GigaAM-CTC\n",
    "print(\"Загрузка модели GigaAM-CTC...\")\n",
    "model = gigaam.load_model(\"ctc\")  # или \"v2_ctc\" для второй версии\n",
    "print(\"✓ Модель загружена успешно!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Тестирование на одном образце"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тест на одном образце из dev set\n",
    "sample = dev_data.iloc[0]\n",
    "reference = normalize_text(sample['raw_text'])\n",
    "\n",
    "print(\"Тестирование модели на одном образце...\")\n",
    "print(f\"ID: {sample['id']}\")\n",
    "\n",
    "# Создаем временный файл для аудио\n",
    "with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:\n",
    "    tmp_path = tmp_file.name\n",
    "    sf.write(tmp_path, sample['audio_array'], sample['sampling_rate'])\n",
    "\n",
    "# Транскрибация\n",
    "prediction = model.transcribe(tmp_path)\n",
    "prediction_normalized = normalize_text(prediction)\n",
    "\n",
    "# Удаляем временный файл\n",
    "import os as os_module\n",
    "os_module.unlink(tmp_path)\n",
    "\n",
    "print(f\"\\nReference:  {reference}\")\n",
    "print(f\"Prediction: {prediction_normalized}\")\n",
    "print(f\"\\nСовпадение: {reference == prediction_normalized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Инференс на валидационном наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, data_df):\n",
    "    \"\"\"\n",
    "    Запуск инференса на датасете\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    for idx, row in tqdm(data_df.iterrows(), total=len(data_df), desc=\"Inference\"):\n",
    "        try:\n",
    "            # Создаем временный файл\n",
    "            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:\n",
    "                tmp_path = tmp_file.name\n",
    "                sf.write(tmp_path, row['audio_array'], row['sampling_rate'])\n",
    "            \n",
    "            # Транскрибация\n",
    "            prediction = model.transcribe(tmp_path)\n",
    "            prediction = normalize_text(prediction)\n",
    "            \n",
    "            # Удаляем временный файл\n",
    "            os_module.unlink(tmp_path)\n",
    "            \n",
    "            reference = normalize_text(row['raw_text'])\n",
    "            predictions.append(prediction)\n",
    "            references.append(reference)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing sample {row['id']}: {e}\")\n",
    "            predictions.append(\"\")\n",
    "            references.append(normalize_text(row['raw_text']))\n",
    "            # Очистка в случае ошибки\n",
    "            if os_module.path.exists(tmp_path):\n",
    "                os_module.unlink(tmp_path)\n",
    "    \n",
    "    return predictions, references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск инференса на валидационном наборе\n",
    "print(\"Запуск инференса на валидационном наборе...\")\n",
    "predictions, references = run_inference(model, dev_data)\n",
    "\n",
    "# Сохранение результатов\n",
    "results_df = pd.DataFrame({\n",
    "    'audio_id': dev_data['id'].values,\n",
    "    'reference': references,\n",
    "    'prediction': predictions\n",
    "})\n",
    "\n",
    "results_df.to_csv('dev_predictions.csv', index=False)\n",
    "print(\"\\n✓ Результаты сохранены в dev_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Расчет метрик WER и CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтрация валидных пар (reference, prediction)\n",
    "valid_pairs = [(ref, pred) for ref, pred in zip(references, predictions) \n",
    "               if pred and ref]\n",
    "\n",
    "if valid_pairs:\n",
    "    references_valid, predictions_valid = zip(*valid_pairs)\n",
    "    \n",
    "    # Расчет метрик\n",
    "    wer_score = wer(references_valid, predictions_valid)\n",
    "    cer_score = cer(references_valid, predictions_valid)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"РЕЗУЛЬТАТЫ ОЦЕНКИ\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Всего образцов: {len(dev_data)}\")\n",
    "    print(f\"Валидных предсказаний: {len(valid_pairs)}\")\n",
    "    print(f\"\\nМетрики:\")\n",
    "    print(f\"  Word Error Rate (WER):      {wer_score*100:.2f}%\")\n",
    "    print(f\"  Character Error Rate (CER): {cer_score*100:.2f}%\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Проверка достижения цели\n",
    "    if wer_score < 0.08:\n",
    "        print(f\"\\n✓ УСПЕХ! Целевой WER < 8% достигнут!\")\n",
    "        print(f\"  Текущий WER: {wer_score*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"\\n✗ Целевой WER не достигнут\")\n",
    "        print(f\"  Текущий WER: {wer_score*100:.2f}%\")\n",
    "        print(f\"  Цель: < 8.00%\")\n",
    "        print(f\"  Разница: +{(wer_score - 0.08)*100:.2f}%\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"Нет валидных предсказаний для расчета метрик!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Анализ результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Показать примеры правильных предсказаний\n",
    "print(\"Примеры ПРАВИЛЬНЫХ предсказаний:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "correct_count = 0\n",
    "for i, (ref, pred) in enumerate(zip(references_valid, predictions_valid)):\n",
    "    if ref == pred and correct_count < 5:\n",
    "        print(f\"\\n[Пример {correct_count + 1}]\")\n",
    "        print(f\"Text: {ref}\")\n",
    "        correct_count += 1\n",
    "\n",
    "print(f\"\\nВсего точных совпадений: {sum(1 for r, p in zip(references_valid, predictions_valid) if r == p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Показать примеры с ошибками\n",
    "print(\"\\nПримеры предсказаний С ОШИБКАМИ:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "error_count = 0\n",
    "for i, (ref, pred) in enumerate(zip(references_valid, predictions_valid)):\n",
    "    if ref != pred and error_count < 5:\n",
    "        print(f\"\\n[Пример {error_count + 1}]\")\n",
    "        print(f\"Reference:  {ref}\")\n",
    "        print(f\"Prediction: {pred}\")\n",
    "        error_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. (Опционально) Инференс на тестовом наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Раскомментируйте для запуска на тестовом наборе\n",
    "# print(\"Запуск инференса на тестовом наборе...\")\n",
    "# test_predictions, test_references = run_inference(model, test_data)\n",
    "\n",
    "# # Сохранение результатов\n",
    "# test_results_df = pd.DataFrame({\n",
    "#     'audio_id': test_data['id'].values,\n",
    "#     'reference': test_references,\n",
    "#     'prediction': test_predictions\n",
    "# })\n",
    "\n",
    "# test_results_df.to_csv('test_predictions.csv', index=False)\n",
    "# print(\"✓ Результаты сохранены в test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заключение\n",
    "\n",
    "В этом ноутбуке мы:\n",
    "\n",
    "1. ✓ Установили необходимые зависимости\n",
    "2. ✓ Загрузили данные FLEURS напрямую из HuggingFace Hub\n",
    "3. ✓ Загрузили предобученную модель GigaAM-CTC\n",
    "4. ✓ Запустили инференс на валидационном наборе\n",
    "5. ✓ Рассчитали метрики WER и CER\n",
    "6. ✓ Проанализировали результаты\n",
    "\n",
    "### Ожидаемые результаты\n",
    "\n",
    "Предобученная модель GigaAM-CTC-v2 уже показывает отличные результаты на русском языке и, вероятно, достигнет целевого WER < 8% без дополнительного дообучения.\n",
    "\n",
    "Если WER выше 8%, можно попробовать:\n",
    "- Использовать модель GigaAM-RNNT (более точная)\n",
    "- Провести fine-tuning на датасете FLEURS\n",
    "- Использовать beam search декодирование\n",
    "- Добавить языковую модель для пост-обработки"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}